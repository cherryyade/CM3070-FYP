{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7190954c",
   "metadata": {},
   "source": [
    "## Student ID: 190428550"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfb3d5f",
   "metadata": {},
   "source": [
    "### Machine Learning and Neural Networks - Template (1)\n",
    "### Deep Learning on a Public Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035ad7cf",
   "metadata": {},
   "source": [
    "##### *This notebook will contain the third iteration of our project, where we will use the models that we previously created to create a model ensemble. Model ensembling produces results that are more accurate than singular models. This is a continuation of the 5th iteration. Any new findings will be reported in new sections.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ea7aec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbfdefb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.python.keras import utils\n",
    "from tensorflow.keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cd22cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>HourOfDay</th>\n",
       "      <th>Delayed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3451752</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>CO</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ORD</td>\n",
       "      <td>719</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5577044</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>XE</td>\n",
       "      <td>SAV</td>\n",
       "      <td>EWR</td>\n",
       "      <td>708</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731620</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>NW</td>\n",
       "      <td>DTW</td>\n",
       "      <td>BWI</td>\n",
       "      <td>408</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6053324</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>WN</td>\n",
       "      <td>LAS</td>\n",
       "      <td>ONT</td>\n",
       "      <td>197</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746335</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NW</td>\n",
       "      <td>DTW</td>\n",
       "      <td>ABE</td>\n",
       "      <td>424</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Month  DayOfWeek UniqueCarrier Origin Dest  Distance  HourOfDay  \\\n",
       "3451752      6          7            CO    EWR  ORD       719          8   \n",
       "5577044     10          7            XE    SAV  EWR       708         17   \n",
       "731620       2          6            NW    DTW  BWI       408         13   \n",
       "6053324     11          5            WN    LAS  ONT       197         17   \n",
       "746335       2          1            NW    DTW  ABE       424         13   \n",
       "\n",
       "         Delayed  \n",
       "3451752        0  \n",
       "5577044        0  \n",
       "731620         0  \n",
       "6053324        1  \n",
       "746335         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airplane_data = pd.read_csv(\"2004.csv\")\n",
    "airplane_data = airplane_data.sample(n=100000)\n",
    "\n",
    "airplane_data['CRSDepTime'] = airplane_data['CRSDepTime'].astype(str)\n",
    "length_of_crsdeptime = airplane_data['CRSDepTime'].str.len()\n",
    "airplane_data['HourOfDay'] = np.select([length_of_crsdeptime==4, length_of_crsdeptime==3, length_of_crsdeptime<3], [airplane_data['CRSDepTime'].str[0:2], airplane_data['CRSDepTime'].str[0:1], 0], np.nan)\n",
    "airplane_data['HourOfDay'] = airplane_data['HourOfDay'].astype(int)\n",
    "\n",
    "airplane_data['Delayed'] = np.where(airplane_data['ArrDelay'] > 15, 1, 0)\n",
    "airplane_data = airplane_data[['Month', 'DayOfWeek', 'UniqueCarrier', 'Origin', 'Dest', 'Distance', 'HourOfDay', 'Delayed']]\n",
    "\n",
    "airplane_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "472762e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    df = dataframe.copy()\n",
    "    labels = df.pop('Delayed')\n",
    "    df = {key: value[:,tf.newaxis] for key, value in dataframe.items()}\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "        ds = ds.batch(batch_size)\n",
    "        ds = ds.prefetch(batch_size)\n",
    "        return ds\n",
    "    \n",
    "test_ds = df_to_dataset(airplane_data, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1de7905",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = tf.keras.models.load_model('flight_delay_classifier_first')\n",
    "m2 = tf.keras.models.load_model('flight_delay_classifier_second')\n",
    "m3 = tf.keras.models.load_model('flight_delay_classifier_third')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9e2013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0490538b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 2s 2ms/step - loss: 0.4870 - accuracy: 0.8080 - auc: 0.5869\n",
      "391/391 [==============================] - 2s 2ms/step - loss: 0.4878 - accuracy: 0.8080 - auc: 0.5603\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.4814 - accuracy: 0.8080 - auc: 0.5896\n",
      " \n",
      "The loss of model 1 is:  0.4869658648967743\n",
      "The loss of model 2 is:  0.48777273297309875\n",
      "The loss of model 3 is:  0.4813674986362457\n",
      " \n",
      "The accuracy of model 1 is:  0.8079500198364258\n",
      "The accuracy of model 2 is:  0.8079800009727478\n",
      "The accuracy of model 3 is:  0.8079699873924255\n",
      "\n",
      "The AUC of model 1 is:  0.5869275331497192\n",
      "The AUC of model 2 is:  0.5602584481239319\n",
      "The AUC of model 3 is:  0.589623212814331\n"
     ]
    }
   ],
   "source": [
    "loss1, accuracy1, auc1 = m1.evaluate(test_ds)\n",
    "loss2, accuracy2, auc2 = m2.evaluate(test_ds)\n",
    "loss3, accuracy3, auc3 = m3.evaluate(test_ds)\n",
    "\n",
    "print(\" \")\n",
    "print(\"The loss of model 1 is: \", loss1)\n",
    "print(\"The loss of model 2 is: \", loss2)\n",
    "print(\"The loss of model 3 is: \", loss3)\n",
    "print(\" \")\n",
    "print(\"The accuracy of model 1 is: \", accuracy1)\n",
    "print(\"The accuracy of model 2 is: \", accuracy2)\n",
    "print(\"The accuracy of model 3 is: \", accuracy3)\n",
    "print(\"\")\n",
    "print(\"The AUC of model 1 is: \", auc1)\n",
    "print(\"The AUC of model 2 is: \", auc2)\n",
    "print(\"The AUC of model 3 is: \", auc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37692c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 241ms/step\n",
      "Using Model 1 to predict, this particular flight had a 57.9 percent probability of getting delayed.\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "Using Model 2 to predict, this particular flight had a 56.0 percent probability of getting delayed.\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "Using Model 3 to predict, this particular flight had a 56.4 percent probability of getting delayed.\n"
     ]
    }
   ],
   "source": [
    "sample = {\n",
    "    'Month': 1,\n",
    "    'DayOfWeek': 1,\n",
    "    'UniqueCarrier': 'NW',\n",
    "    'Origin': 'HNL',\n",
    "    'Dest': 'SEA',\n",
    "    'Distance': 2677,\n",
    "    'HourOfDay': 14,    \n",
    "}\n",
    "\n",
    "# MODEL 1 \n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "predictions = m1.predict(input_dict)\n",
    "prob = tf.nn.sigmoid(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"Using Model 1 to predict, this particular flight had a %.1f percent probability \"\n",
    "    \"of getting delayed.\" % (100 * prob)\n",
    ")\n",
    "\n",
    "# MODEL 2 \n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "predictions = m2.predict(input_dict)\n",
    "prob = tf.nn.sigmoid(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"Using Model 2 to predict, this particular flight had a %.1f percent probability \"\n",
    "    \"of getting delayed.\" % (100 * prob)\n",
    ")\n",
    "\n",
    "# MODEL 3 \n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "predictions = m3.predict(input_dict)\n",
    "prob = tf.nn.sigmoid(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"Using Model 3 to predict, this particular flight had a %.1f percent probability \"\n",
    "    \"of getting delayed.\" % (100 * prob)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7fe9d43",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "This particular flight had a 56.7 percent probability of getting delayed.\n"
     ]
    }
   ],
   "source": [
    "#Ensembling consists of pooling together the predictions of a set of different models, to produce better predictions\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "\n",
    "preds_a = m1.predict(input_dict)\n",
    "preds_b = m2.predict(input_dict)\n",
    "preds_c = m3.predict(input_dict)\n",
    "final_preds = 0.33 * preds_a + 0.33 * preds_b + 0.33 * preds_c\n",
    "\n",
    "prob = tf.nn.sigmoid(final_preds)\n",
    "\n",
    "print(\n",
    "    \"This particular flight had a %.1f percent probability \"\n",
    "    \"of getting delayed.\" % (100 * prob)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd4095a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
